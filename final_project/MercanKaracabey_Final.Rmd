---
title: "Final_Document"
author: "Mercan Karacabey"
date: "05 01 2019"
output: pdf_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## PART 1

  1. What is your opinion about Python vs R debate? To what extent do you agree with the post on https://www.dataschool.io/python-or-r-for-data-science/? Be honest, you wonâ€™t be penalized or rewarded for stating your opinions; only by the quality your arguments.
   
    * I started to learn programming language at university with Python, so it was hard for me to learn R programming.However, for people who have just begun programming, R may be a better   choice for producing output by writing fewer codes.(It is quite important to obtain particularly visible outputs for new programmer :)) In terms of visualization, R is more successful     than Python to produce more complex visuals. In terms of machine learning and statistical learning; Python is more successful in machine learning, because the more practical preparation   of the learning models and the back-end libraries are more complex. R more successful in statistical learning. Because of the practical functions used in mathematical modeling can         provide rapid solutions. In terms of integrated work with distributed architectures, python's methodologies are more successful. For the scientists who will produce outputs on             mathematical models, R is more convenient for practicality. In summary, in my opinion, data engineers will prefer python and data scientists will prefer R.
  
  
  2. What is your exploratory data analysis workflow? Suppose you are given a data set and a research question. Where do you start? How do you proceed? For instance, you are given the task to distribute funds from donations to public welfare projects in a wide range of subjects (e.g. education, gender equality, poverty, job creation, healthcare) with the objective of maximum positive impact on the society in general. Assume you have almost all the data you require. How do you measure impact? How do you form performance measures? What makes you think you find an interesting angle?
  
    * Firstly, I analyze what types of data they contain, and the relationship between them if there are other linked data. The operation is performed on the data by                         cleaning.Discrimination analysis, outlier analysis etc. can be carried out at this stage. Algorithms are deduced by deciding which machine learning or statistical learning is used.(Maybe   used both of them.) The output generated by data visualization is interpreted by enriching the output. As it is a social issue about interpretation, I take the increasing benefit as a     criterion for measurement.
 
 
  3. If you had to plot a single graph using the flights data what would it be? Why? Make your argument, actually code the plot and provide the output. (You can find detailed info about the movies data set in its help file. Use ?flights, after you load nycflights13 package.)
  
    * I would like a plot a graph regarding carrier vs air delay. A plot is designed for the purpose of evaluating the carrier based on a minimum of flight delay.Without outliers, the most rapid carrier can be found.
  
```{r question1-3-f}
library(dplyr) 
library(nycflights13) 
library(ggplot2)
glimpse(flights)
```

```{r question1-3-s}
ggplot(flights, aes(flights$carrier, flights$arr_delay,colour = flights$month)) + 
  geom_point()
```

## PART 2

*In previous analyzes, only export / import analysis was performed on a date basis.
*In addition, Export / Import ratio depending on dollar exchange rate.
*It was observed that both decreases due to the sudden increase in the dollar exchange rate.
*Correlation table was created.(Consumer Price Index/ USD Rate / Import-Export Amounts)
*The correlation values are shown in the table depending on the data in the confidence interval.(0.95)
*The regression line is drawn. Analysis was made with and without confidence interval. In addition, drawing using the Loess method

```{r, warning=FALSE}
#required packages
library("tidyverse")
library("readxl")
library("ggplot2")
library("plotly")
library("gapminder")
library("dplyr")
```

#### Download RDS Data from Github Page

```{r, warning=FALSE}
tmp<-tempfile(fileext=".rds")
download.file("https://github.com/MEF-BDA503/gpj18-r_coders/blob/master/Data_Sources_Rds/imp_data_final.rds?raw=true",
              destfile=tmp,mode = 'wb')
imp_data_final<-read_rds(tmp)
file.remove(tmp)


tmp<-tempfile(fileext=".rds")
download.file("https://github.com/MEF-BDA503/gpj18-r_coders/blob/master/Data_Sources_Rds/exp_data_final.rds?raw=true",
              destfile=tmp,mode = 'wb')
exp_data_final<-read_rds(tmp)
file.remove(tmp)


tmp<-tempfile(fileext=".rds")
download.file("https://github.com/MEF-BDA503/gpj18-r_coders/blob/master/Data_Sources_Rds/imp_data.rds?raw=true?raw=true",
              destfile=tmp,mode = 'wb')
imp_data<-read_rds(tmp)
file.remove(tmp)


tmp<-tempfile(fileext=".rds")
download.file("https://github.com/MEF-BDA503/gpj18-r_coders/blob/master/Data_Sources_Rds/exp_data.rds?raw=true?raw=true",
              destfile=tmp,mode = 'wb')
exp_data<-read_rds(tmp)
file.remove(tmp)

tmp<-tempfile(fileext=".rds")
download.file("https://github.com/MEF-BDA503/gpj18-r_coders/blob/master/Data_Sources_Rds/Producer_Inflation.rds?raw=true",
              destfile=tmp,mode = 'wb')
producer_inf<-read_rds(tmp)
file.remove(tmp)

# Create a temporary file
tmp=tempfile(fileext=".xls")
# Download file from repository to the temp file
download.file("https://github.com/MEF-BDA503/gpj18-r_coders/blob/master/Data_Sources_Excel/export_import_sectors.xls?raw=true",
              destfile=tmp,mode='wb')
# Read that excel file.
sectors <- read_excel(tmp)
# Remove the temp file
file.remove(tmp)

tmp<-tempfile(fileext=".rds")
download.file("https://github.com/MEF-BDA503/gpj18-r_coders/blob/master/Data_Sources_Rds/US_Dollar_Montly_Rate.rds?raw=true",
              destfile=tmp,mode = 'wb')
usd_rate<-read_rds(tmp)
file.remove(tmp)
```

##### Format Data
For exploratory data analysis, I put this stage(Data preparation)
```{r, warning=FALSE}
names(exp_data_final)[names(exp_data_final) == 'Date'] <- 'Export_Date'
names(exp_data)[names(exp_data) == 'Date'] <- 'Export_Date'
names(imp_data_final)[names(imp_data_final) == 'Date'] <- 'Import_Date'
names(imp_data_final)[names(imp_data_final) == 'Export_Total_Amount']<-'Import_Total_Amount'
names(imp_data)[names(imp_data) == 'Date'] <- 'Import_Date'

library("dplyr")
exp_data <- inner_join(exp_data,sectors, by=c("Sector_Type_Code"="Sub_Sector_Type_Code"))

imp_data <- inner_join(imp_data,sectors, by=c("Sector_Type_Code"="Sub_Sector_Type_Code"))

exp_data$Export_Year<-as.numeric(format(exp_data$Export_Date,"%Y"))
exp_data$Export_Year_Month<-format(exp_data$Export_Date,"%Y-%m")
exp_data_final$Export_Year<-as.numeric(format(exp_data_final$Export_Date,"%Y"))
exp_data_final$Export_Year_Month<-format(exp_data_final$Export_Date,"%Y-%m")

imp_data$Import_Year<-as.numeric(format(imp_data$Import_Date,"%Y"))
imp_data$Import_Year_Month<-format(imp_data$Import_Date,"%Y-%m")
imp_data_final$Import_Year<-as.numeric(format(imp_data_final$Import_Date,"%Y"))
imp_data_final$Import_Year_Month<-format(imp_data_final$Import_Date,"%Y-%m")

imp_data<- imp_data %>%
  select (Import_Date,Sector_Type_Code,Sector_Type_Code.y,Main_Sector_Flag,Sector_Name_Eng,
          Amount,Import_Year,Import_Year_Month)
exp_data<- exp_data %>%
  select (Export_Date,Sector_Type_Code,Sector_Type_Code.y,Main_Sector_Flag,Sector_Name_Eng,
          Amount,Export_Year,Export_Year_Month)  

colnames(imp_data)[colnames(imp_data) == 'Amount'] <- 'Import_Amount'
colnames(exp_data)[colnames(exp_data) == 'Amount'] <- 'Export_Amount'
colnames(imp_data)[colnames(imp_data) == 'Sector_Type_Code'] <- 'Sub_Sector_Type_Code'
colnames(exp_data)[colnames(exp_data) == 'Sector_Type_Code'] <- 'Sub_Sector_Type_Code'
colnames(imp_data)[colnames(imp_data) == 'Sector_Type_Code.y'] <- 'Sector_Type_Code'
colnames(exp_data)[colnames(exp_data) == 'Sector_Type_Code.y'] <- 'Sector_Type_Code'
imp_data$Import_Amount[is.na(imp_data$Import_Amount)] <- 0
imp_data_final$Import_Total_Amount[is.na(imp_data_final$Import_Total_Amount)] <- 0
exp_data$Export_Amount[is.na(exp_data$Export_Amount)] <- 0
exp_data_final$Export_Total_Amount[is.na(exp_data_final$Export_Total_Amount)] <- 0


exp_data_final <- exp_data_final %>%
  filter(Export_Date<'2018-11-01')

exp_data <- exp_data %>%
  filter(Export_Date<'2018-11-01')

imp_data_final <- imp_data_final %>%
  filter(Import_Date<'2018-11-01')

imp_data <- imp_data %>%
  filter(Import_Date<'2018-11-01')

saveRDS(imp_data,file="imp_data_v2.rds")
saveRDS(imp_data_final,file="imp_data_final_v2.rds")
saveRDS(exp_data,file="exp_data_v2.rds")
saveRDS(exp_data_final,file="exp_data_final_v2.rds")
```

Prepare Data and Import&Export Line Graph 

*In previous analyzes, only export / import analysis was performed on a date basis.
*In addition, Export / Import ratio depending on dollar exchange rate.
*It was observed that both decreases due to the sudden increase in the dollar exchange rate.
*Correlation table was created.(Consumer Price Index/ USD Rate / Import-Export Amounts)
*The correlation values are shown in the table depending on the data in the confidence interval.(0.95)
*The regression line is drawn. Analysis was made with and without confidence interval. In addition, drawing using the Loess method

```{r, warning=FALSE }
imp_and_exp_data <- inner_join(exp_data, imp_data, by=c("Export_Date" = "Import_Date","Sub_Sector_Type_Code"="Sub_Sector_Type_Code"))

imp_and_exp_data_bymonth <- aggregate(cbind(Import_Amount, Export_Amount) ~ Export_Date, data = imp_and_exp_data, sum)
imp_and_exp_data_bymonth <- gather(imp_and_exp_data_bymonth,
                               value = "value",
                               key = "type",
                               Export_Amount, Import_Amount)

#Rename column names
colnames(imp_and_exp_data_bymonth) <- c("Date","Type","Amount")

#Remove Empty Dates
imp_and_exp_data_bymonth <- imp_and_exp_data_bymonth %>%
  filter(Date<'2018-11-01')

imp_and_exp_data_final_1 <- inner_join(exp_data_final, imp_data_final, by=c("Export_Date" = "Import_Date"))


imp_and_exp_data_bymonth_final <- aggregate(cbind(Import_Total_Amount, Export_Total_Amount) ~ USD_Rate.y, data = imp_and_exp_data_final_1, sum)
imp_and_exp_data_bymonth_final <- gather(imp_and_exp_data_bymonth_final,
                               value = "value",
                               key = "type",
                               Export_Total_Amount, Import_Total_Amount)

#Rename column names
colnames(imp_and_exp_data_bymonth_final) <- c("USD_Rate","Type","Amount")

 p<-ggplot(imp_and_exp_data_bymonth_final,
        aes(x=USD_Rate,
            y=Amount/1000,
            color=Type)) +
   geom_line()+
   scale_size_area("Nitrogen") + 
   xlab("USD Rate") +
   ylab("Amount  (Million $)") +
   ggtitle("Import & Export Amount")
 style(p, text = row.names(imp_and_exp_data_bymonth))
 p
``` 
 
- Corelation Matrix 
```{r, warning=FALSE }
temp_table <- imp_and_exp_data_final_1 %>% select(Export_Total_Amount,Consumer_Price_Index_Monthly_Change.x,Consumer_Price_Index_Yearly_Change.y,Import_Total_Amount,USD_Rate.y)


names(temp_table)[names(temp_table) == "Export_Total_Amount"] <- "Exp.Amount"

names(temp_table)[names(temp_table) == "Import_Total_Amount"] <- "Imp.Amount"

names(temp_table)[names(temp_table) == "Consumer_Price_Index_Monthly_Change.x"] <- "ConsumerPriceX"


names(temp_table)[names(temp_table) == "Consumer_Price_Index_Yearly_Change.y"] <- "ConsumerPriceY"

names(temp_table)[names(temp_table) == "USD_Rate.y"] <- "USD_R"


corelation_matrix <- cor(temp_table)

corelation_matrix
```

Corelation Matrix - Graph
```{r, warning=FALSE }
library(corrplot)

cor.mtest <- function(mat, conf.level = 0.95) {
  mat <- as.matrix(mat)
  n <- ncol(mat)
  p.mat <- lowCI.mat <- uppCI.mat <- matrix(NA, n, n)
  diag(p.mat) <- 0
  diag(lowCI.mat) <- diag(uppCI.mat) <- 1
  for (i in 1:(n - 1)) {
    for (j in (i + 1):n) {
      tmp <- cor.test(mat[, i], mat[, j], conf.level = conf.level)
      p.mat[i, j] <- p.mat[j, i] <- tmp$p.value
      lowCI.mat[i, j] <- lowCI.mat[j, i] <- tmp$conf.int[1]
      uppCI.mat[i, j] <- uppCI.mat[j, i] <- tmp$conf.int[2]
    }
  }
  return(list(p.mat, lowCI.mat, uppCI.mat))
}

res <- cor.mtest(temp_table, 0.95)
corrplot(corelation_matrix, method = "circle", order = "hclust", p.mat = res[[1]], sig.level = 0.05, addrect = 2, tl.col="black", tl.srt=45)
```

Regression Graph
```{r, warning=FALSE }
# Regresyon doÄŸrusu eklemek
ggplot(temp_table, aes(x=ConsumerPriceY, y=USD_R)) +
geom_point()+
geom_smooth(method=lm)
```

Remove Confidence Interval and Draw Graph
```{r, warning=FALSE }
# GÃ¼ven aralÄ±ÄŸÄ± kaldÄ±rÄ±ldÄ±ÄŸÄ±nda
ggplot(temp_table, aes(x=ConsumerPriceY, y=USD_R)) +
geom_point()+
geom_smooth(method=lm, se=FALSE)
```

Loess method
```{r, warning=FALSE }
# Loess metodu
ggplot(temp_table, aes(x=ConsumerPriceY, y=USD_R)) +
geom_point()+
geom_smooth()
```


<!-- ## PART 3 -->

<!-- ```{r part3} -->
<!-- tmp<-tempfile(fileext=".rds") -->
<!-- download.file("https://github.com/MEF-BDA503/pj18-efehandanisman/blob/master/timeshighereducation/ranking2019.rds?raw=true?raw=true", -->
<!--               destfile=tmp,mode = 'wb') -->
<!-- education_data <-read_rds(tmp) -->
<!-- education_data -->
<!-- ``` -->


<!-- b) The correlation between: As a student in the industry, the number of students, the number of students, the number of studies and the ranking was investigated. -->


<!-- ```{r part3b-1, echo=FALSE} -->

<!-- education_data$scores_research_rank <-suppressWarnings(as.numeric(education_data$scores_research_rank)) -->
<!-- education_data$rank <- suppressWarnings(as.numeric(education_data$rank)) -->
<!-- education_data$scores_industry_income <- suppressWarnings(as.numeric(education_data$scores_industry_income)) -->
<!-- education_data$stats_number_students <- suppressWarnings(as.numeric(education_data$stats_number_students)) -->

<!-- nEducationData <- education_data %>% select(scores_research_rank,rank,scores_industry_income,stats_number_students) -->


<!-- corelation_matrix <- cor(nEducationData) -->


<!-- library(corrplot) -->

<!-- cor.mtest <- function(mat, conf.level = 0.95) { -->
<!--   mat <- as.matrix(mat) -->
<!--   n <- ncol(mat) -->
<!--   p.mat <- lowCI.mat <- uppCI.mat <- matrix(NA, n, n) -->
<!--   diag(p.mat) <- 0 -->
<!--   diag(lowCI.mat) <- diag(uppCI.mat) <- 1 -->
<!--   for (i in 1:(n - 1)) { -->
<!--     for (j in (i + 1):n) { -->
<!--       tmp <- cor.test(mat[, i], mat[, j], conf.level = conf.level) -->
<!--       p.mat[i, j] <- p.mat[j, i] <- tmp$p.value -->
<!--       lowCI.mat[i, j] <- lowCI.mat[j, i] <- tmp$conf.int[1] -->
<!--       uppCI.mat[i, j] <- uppCI.mat[j, i] <- tmp$conf.int[2] -->
<!--     } -->
<!--   } -->
<!--   return(list(p.mat, lowCI.mat, uppCI.mat)) -->
<!-- } -->

<!-- res <- cor.mtest(nEducationData, 0.25) -->
<!-- corrplot(corelation_matrix, method = "circle", order = "hclust", p.mat = res[[1]], sig.level = 0.05, addrect = 2, tl.col="black", tl.srt=45) -->

<!-- ``` -->

<!-- Values that appear to be correlated with a small scale are shown on the graph. However, it is not possible to comment on a relationship from the output of the graph. -->

<!-- ```{r part3-b-2, echo=FALSE} -->
<!-- p <- ggplot(education_data, aes(x= education_data$scores_research_rank  , y=  education_data$rank)) + -->
<!--   xlab("scores_research_rank") + -->
<!--   ylab("rank") + -->
<!--   ggtitle("Rank/Scores_research_rank")+ -->
<!--   geom_point(stat='identity', aes(col=education_data$stats_number_students), size=6) -->
<!-- p + theme(axis.text.x = element_text(angle = 90, hjust = 1)) -->
<!-- ggplotly(p) -->
<!-- ``` -->
